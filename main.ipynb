{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cd52099",
   "metadata": {},
   "source": [
    "# Predicting Income Using Census Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978823f3",
   "metadata": {},
   "source": [
    "This project is aimed at predicting whether an individual's income is greater than $50K or not using a \"Census Income\" dataset. The features include age, workclass, education, and race etc. This is a supervised classification problem since the dataset has the ground truth label in the `income` column.\n",
    "\n",
    "In specific, we need to build a model to predict whether an individual's income is over $50 or not given all the features. Build an accurate model like this can be helpful in data management, e.g. predicting a missing income label.\n",
    "\n",
    "The dataset was created by Barry Becker and Ronny Kohavi from the 1994 Census database and is downloaded from the UCI ML Repository.\n",
    "\n",
    "```\n",
    "Becker,Barry and Kohavi,Ronny. (1996). Adult. UCI Machine Learning Repository. https://doi.org/10.24432/C5XW20.\n",
    "\n",
    "@misc{misc_adult_2,\n",
    "  author       = {Becker,Barry and Kohavi,Ronny},\n",
    "  title        = {{Adult}},\n",
    "  year         = {1996},\n",
    "  howpublished = {UCI Machine Learning Repository},\n",
    "  note         = {{DOI}: https://doi.org/10.24432/C5XW20}\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "7cd0f0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, RidgeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, BaggingClassifier\n",
    "\n",
    "from sklearn.feature_selection import SelectPercentile, chi2\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "seed = 168\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2734972c",
   "metadata": {},
   "source": [
    "# 1. EDA & Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1416719f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch dataset\n",
    "adult = fetch_ucirepo(id=2)\n",
    "\n",
    "# data (as pandas dataframes)\n",
    "X = adult.data.features\n",
    "y = adult.data.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "54d83624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  education-num  \\\n",
       "0   39         State-gov   77516  Bachelors             13   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2   38           Private  215646    HS-grad              9   \n",
       "3   53           Private  234721       11th              7   \n",
       "4   28           Private  338409  Bachelors             13   \n",
       "\n",
       "       marital-status         occupation   relationship   race     sex  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week native-country  \n",
       "0          2174             0              40  United-States  \n",
       "1             0             0              13  United-States  \n",
       "2             0             0              40  United-States  \n",
       "3             0             0              40  United-States  \n",
       "4             0             0              40           Cuba  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ddad5be5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  income\n",
       "0  <=50K\n",
       "1  <=50K\n",
       "2  <=50K\n",
       "3  <=50K\n",
       "4  <=50K"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7ed89a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48842 entries, 0 to 48841\n",
      "Data columns (total 14 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             48842 non-null  int64 \n",
      " 1   workclass       47879 non-null  object\n",
      " 2   fnlwgt          48842 non-null  int64 \n",
      " 3   education       48842 non-null  object\n",
      " 4   education-num   48842 non-null  int64 \n",
      " 5   marital-status  48842 non-null  object\n",
      " 6   occupation      47876 non-null  object\n",
      " 7   relationship    48842 non-null  object\n",
      " 8   race            48842 non-null  object\n",
      " 9   sex             48842 non-null  object\n",
      " 10  capital-gain    48842 non-null  int64 \n",
      " 11  capital-loss    48842 non-null  int64 \n",
      " 12  hours-per-week  48842 non-null  int64 \n",
      " 13  native-country  48568 non-null  object\n",
      "dtypes: int64(6), object(8)\n",
      "memory usage: 5.2+ MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f87a502",
   "metadata": {},
   "source": [
    "There are several features that have missing values and need to be dealt with. Let's check the percentage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1077dfef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age               0.000000\n",
       "workclass         0.019717\n",
       "fnlwgt            0.000000\n",
       "education         0.000000\n",
       "education-num     0.000000\n",
       "marital-status    0.000000\n",
       "occupation        0.019778\n",
       "relationship      0.000000\n",
       "race              0.000000\n",
       "sex               0.000000\n",
       "capital-gain      0.000000\n",
       "capital-loss      0.000000\n",
       "hours-per-week    0.000000\n",
       "native-country    0.005610\n",
       "dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdcaf59",
   "metadata": {},
   "source": [
    "Next, examine general data characteristics and make plots to identify potential data issues, such as outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "73041f7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>48842.000000</td>\n",
       "      <td>4.884200e+04</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.643585</td>\n",
       "      <td>1.896641e+05</td>\n",
       "      <td>10.078089</td>\n",
       "      <td>1079.067626</td>\n",
       "      <td>87.502314</td>\n",
       "      <td>40.422382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.710510</td>\n",
       "      <td>1.056040e+05</td>\n",
       "      <td>2.570973</td>\n",
       "      <td>7452.019058</td>\n",
       "      <td>403.004552</td>\n",
       "      <td>12.391444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.228500e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.175505e+05</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.781445e+05</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>2.376420e+05</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.490400e+06</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>4356.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        fnlwgt  education-num  capital-gain  capital-loss  \\\n",
       "count  48842.000000  4.884200e+04   48842.000000  48842.000000  48842.000000   \n",
       "mean      38.643585  1.896641e+05      10.078089   1079.067626     87.502314   \n",
       "std       13.710510  1.056040e+05       2.570973   7452.019058    403.004552   \n",
       "min       17.000000  1.228500e+04       1.000000      0.000000      0.000000   \n",
       "25%       28.000000  1.175505e+05       9.000000      0.000000      0.000000   \n",
       "50%       37.000000  1.781445e+05      10.000000      0.000000      0.000000   \n",
       "75%       48.000000  2.376420e+05      12.000000      0.000000      0.000000   \n",
       "max       90.000000  1.490400e+06      16.000000  99999.000000   4356.000000   \n",
       "\n",
       "       hours-per-week  \n",
       "count    48842.000000  \n",
       "mean        40.422382  \n",
       "std         12.391444  \n",
       "min          1.000000  \n",
       "25%         40.000000  \n",
       "50%         40.000000  \n",
       "75%         45.000000  \n",
       "max         99.000000  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "fa31f50b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                int64\n",
       "workclass         object\n",
       "fnlwgt             int64\n",
       "education-num      int64\n",
       "marital-status    object\n",
       "occupation        object\n",
       "relationship      object\n",
       "race              object\n",
       "sex               object\n",
       "capital-gain       int64\n",
       "capital-loss       int64\n",
       "hours-per-week     int64\n",
       "native-country    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "3f6051fc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(10, 10))\n",
    "axes = axes.flatten()\n",
    "i = 0\n",
    "\n",
    "for feature, dtype in X.dtypes.items():\n",
    "    if dtype != 'object':\n",
    "        axes[i].hist(X[feature])\n",
    "        axes[i].set_title(feature)\n",
    "        i += 1\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "882a95bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8f095bbeb0>"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# correlation matrix\n",
    "X_numeric = X[[k for k, v in X.dtypes.items() if v!='object']]\n",
    "plt.matshow(X_numeric.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ca7f6e",
   "metadata": {},
   "source": [
    "The distributions are not symetrical, thus we'll use median to impute missing values for numeric features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "89d3cb9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.query('education==\"Bachelors\"')['education-num'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e5b334d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.query('education==\"Some-college\"')['education-num'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a8edc860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.query('education==\"Masters\"')['education-num'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d569a75f",
   "metadata": {},
   "source": [
    "`education` and `education-num` features are thus interchangeable, and we'll only keep `education-num`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "21114a65",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>39</td>\n",
       "      <td>Private</td>\n",
       "      <td>215419</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>321403</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other-relative</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>374983</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>83891</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>5455</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>35</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>182148</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48842 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age         workclass  fnlwgt  education-num      marital-status  \\\n",
       "0       39         State-gov   77516             13       Never-married   \n",
       "1       50  Self-emp-not-inc   83311             13  Married-civ-spouse   \n",
       "2       38           Private  215646              9            Divorced   \n",
       "3       53           Private  234721              7  Married-civ-spouse   \n",
       "4       28           Private  338409             13  Married-civ-spouse   \n",
       "...    ...               ...     ...            ...                 ...   \n",
       "48837   39           Private  215419             13            Divorced   \n",
       "48838   64               NaN  321403              9             Widowed   \n",
       "48839   38           Private  374983             13  Married-civ-spouse   \n",
       "48840   44           Private   83891             13            Divorced   \n",
       "48841   35      Self-emp-inc  182148             13  Married-civ-spouse   \n",
       "\n",
       "              occupation    relationship                race     sex  \\\n",
       "0           Adm-clerical   Not-in-family               White    Male   \n",
       "1        Exec-managerial         Husband               White    Male   \n",
       "2      Handlers-cleaners   Not-in-family               White    Male   \n",
       "3      Handlers-cleaners         Husband               Black    Male   \n",
       "4         Prof-specialty            Wife               Black  Female   \n",
       "...                  ...             ...                 ...     ...   \n",
       "48837     Prof-specialty   Not-in-family               White  Female   \n",
       "48838                NaN  Other-relative               Black    Male   \n",
       "48839     Prof-specialty         Husband               White    Male   \n",
       "48840       Adm-clerical       Own-child  Asian-Pac-Islander    Male   \n",
       "48841    Exec-managerial         Husband               White    Male   \n",
       "\n",
       "       capital-gain  capital-loss  hours-per-week native-country  \n",
       "0              2174             0              40  United-States  \n",
       "1                 0             0              13  United-States  \n",
       "2                 0             0              40  United-States  \n",
       "3                 0             0              40  United-States  \n",
       "4                 0             0              40           Cuba  \n",
       "...             ...           ...             ...            ...  \n",
       "48837             0             0              36  United-States  \n",
       "48838             0             0              40  United-States  \n",
       "48839             0             0              50  United-States  \n",
       "48840          5455             0              40  United-States  \n",
       "48841             0             0              60  United-States  \n",
       "\n",
       "[48842 rows x 13 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.drop(columns=['education'], inplace=True)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10066e27",
   "metadata": {},
   "source": [
    "Next, check the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bf6c01e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "income\n",
       "<=50K     0.506122\n",
       "<=50K.    0.254596\n",
       ">50K      0.160538\n",
       ">50K.     0.078744\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.income.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fb0bb7",
   "metadata": {},
   "source": [
    "Now consolidate the labels and convert to binary labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d27b2482",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.income.replace({'<=50K.': '<=50K', '>50K.': '>50K'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c3c9620e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "income\n",
       "<=50K    0.760718\n",
       ">50K     0.239282\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c24e8d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['<=50K', '>50K'], dtype=object)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(y)\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "86ef6886",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = le.transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d83dc1",
   "metadata": {},
   "source": [
    "We split the data into train, validate and test sets. As the data is imbalanced, we need to make sure the splitting is stratified based on the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "760114f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.25, \n",
    "    random_state=seed, \n",
    "    shuffle=True, \n",
    "    stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "03a98cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_train, X_train_val, y_train_train, y_train_val = train_test_split(\n",
    "    X_train, y_train, \n",
    "    test_size=0.25, \n",
    "    random_state=seed, \n",
    "    shuffle=True, \n",
    "    stratify=y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7abf8168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23928176569346055"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e82f2477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23927820698315636"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bf952de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23929244124150356"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6ead7f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2392894842208714, 0.23924437650141953)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_train.mean(), y_train_val.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adff9c19",
   "metadata": {},
   "source": [
    "Finally, we impute the data. For numeric features, we use the median, for categorical features, we use the mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1177e1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week', ]\n",
    "categorical_features = ['workclass', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d6faa8ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>State-gov</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Private</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Private</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Private</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>Cuba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>Private</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other-relative</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>Private</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>Private</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48842 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              workclass      marital-status         occupation  \\\n",
       "0             State-gov       Never-married       Adm-clerical   \n",
       "1      Self-emp-not-inc  Married-civ-spouse    Exec-managerial   \n",
       "2               Private            Divorced  Handlers-cleaners   \n",
       "3               Private  Married-civ-spouse  Handlers-cleaners   \n",
       "4               Private  Married-civ-spouse     Prof-specialty   \n",
       "...                 ...                 ...                ...   \n",
       "48837           Private            Divorced     Prof-specialty   \n",
       "48838               NaN             Widowed                NaN   \n",
       "48839           Private  Married-civ-spouse     Prof-specialty   \n",
       "48840           Private            Divorced       Adm-clerical   \n",
       "48841      Self-emp-inc  Married-civ-spouse    Exec-managerial   \n",
       "\n",
       "         relationship                race     sex native-country  \n",
       "0       Not-in-family               White    Male  United-States  \n",
       "1             Husband               White    Male  United-States  \n",
       "2       Not-in-family               White    Male  United-States  \n",
       "3             Husband               Black    Male  United-States  \n",
       "4                Wife               Black  Female           Cuba  \n",
       "...               ...                 ...     ...            ...  \n",
       "48837   Not-in-family               White  Female  United-States  \n",
       "48838  Other-relative               Black    Male  United-States  \n",
       "48839         Husband               White    Male  United-States  \n",
       "48840       Own-child  Asian-Pac-Islander    Male  United-States  \n",
       "48841         Husband               White    Male  United-States  \n",
       "\n",
       "[48842 rows x 7 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[categorical_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "be6fca13",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")), \n",
    "        #(\"scaler\", StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")), \n",
    "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "        #(\"selector\", SelectPercentile(chi2, percentile=50)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d0348fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.80000e+01, 3.44415e+05, 1.30000e+01, 0.00000e+00, 0.00000e+00,\n",
       "        3.70000e+01, 0.00000e+00, 1.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 1.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 1.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 1.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        1.00000e+00, 0.00000e+00, 1.00000e+00, 0.00000e+00, 1.00000e+00],\n",
       "       [3.30000e+01, 6.31840e+04, 9.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        4.00000e+01, 0.00000e+00, 1.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 1.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        1.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 1.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        1.00000e+00, 0.00000e+00, 1.00000e+00, 0.00000e+00, 1.00000e+00],\n",
       "       [6.70000e+01, 1.62009e+05, 6.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        1.60000e+01, 0.00000e+00, 1.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        1.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 0.00000e+00, 1.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 1.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        1.00000e+00, 0.00000e+00, 1.00000e+00, 0.00000e+00, 1.00000e+00],\n",
       "       [3.80000e+01, 2.53716e+05, 9.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        4.00000e+01, 0.00000e+00, 1.00000e+00, 0.00000e+00, 1.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 1.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 1.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        1.00000e+00, 0.00000e+00, 1.00000e+00, 0.00000e+00, 1.00000e+00],\n",
       "       [2.70000e+01, 9.12570e+04, 9.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        4.00000e+01, 0.00000e+00, 1.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        1.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 1.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 1.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        1.00000e+00, 0.00000e+00, 1.00000e+00, 1.00000e+00, 0.00000e+00],\n",
       "       [3.80000e+01, 3.31609e+05, 1.00000e+01, 0.00000e+00, 0.00000e+00,\n",
       "        4.70000e+01, 1.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 0.00000e+00, 1.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        1.00000e+00, 0.00000e+00, 1.00000e+00, 0.00000e+00, 1.00000e+00,\n",
       "        0.00000e+00, 1.00000e+00, 0.00000e+00, 0.00000e+00, 1.00000e+00],\n",
       "       [2.00000e+01, 2.98227e+05, 1.00000e+01, 0.00000e+00, 0.00000e+00,\n",
       "        3.50000e+01, 0.00000e+00, 1.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 1.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 1.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 1.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        1.00000e+00, 0.00000e+00, 1.00000e+00, 0.00000e+00, 1.00000e+00],\n",
       "       [4.80000e+01, 2.84970e+04, 9.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        4.00000e+01, 0.00000e+00, 1.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        1.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 1.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 1.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        1.00000e+00, 0.00000e+00, 1.00000e+00, 0.00000e+00, 1.00000e+00],\n",
       "       [2.00000e+01, 1.80339e+05, 9.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        3.50000e+01, 0.00000e+00, 1.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 1.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 1.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 0.00000e+00, 1.00000e+00, 0.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 0.00000e+00, 0.00000e+00, 1.00000e+00],\n",
       "       [4.40000e+01, 5.53950e+04, 9.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        4.00000e+01, 0.00000e+00, 0.00000e+00, 1.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 1.00000e+00, 0.00000e+00, 1.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 1.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        1.00000e+00, 0.00000e+00, 1.00000e+00, 0.00000e+00, 1.00000e+00]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.fit_transform(X_train.sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ae3dbb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 1000\n",
    "sample_idx = np.random.randint(low=0, high=X_train_train.shape[0], size=sample_size)\n",
    "X_sample, y_sample = X_train_train.iloc[sample_idx, :], y_train_train[sample_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "44b6478f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 13), (1000,))"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sample.shape, y_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "7e42055c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = preprocessor.fit_transform(X_train_train)\n",
    "val_X = preprocessor.transform(X_train_val)\n",
    "train_y, val_y = y_train_train, y_train_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e38e151",
   "metadata": {},
   "source": [
    "# 2. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772e577f",
   "metadata": {},
   "source": [
    "First, let's spot-check different types of algorithms to see which one works best with this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "04fc2b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "algos = {\n",
    "    'lr': LogisticRegression(),\n",
    "    'sgd': SGDClassifier(),\n",
    "    'rg': RidgeClassifier(),\n",
    "    'svc': SVC(),\n",
    "    'dt': DecisionTreeClassifier(),\n",
    "    'gnb': GaussianNB(),\n",
    "    'knn': KNeighborsClassifier(),\n",
    "    'gb': GradientBoostingClassifier(),\n",
    "    'rf': RandomForestClassifier(),\n",
    "    'bg': BaggingClassifier()\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for algo, clf in algos.items():\n",
    "    try:\n",
    "        clf.fit(train_X, train_y)\n",
    "        score = clf.score(val_X, val_y)\n",
    "        results[algo] = score\n",
    "    except:\n",
    "        results[algo] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "abe50daf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gb     0.863944\n",
       "rf     0.852042\n",
       "bg     0.848439\n",
       "rg     0.829220\n",
       "dt     0.810002\n",
       "lr     0.797117\n",
       "svc    0.796244\n",
       "knn    0.776916\n",
       "sgd    0.239244\n",
       "gnb         NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(results).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57055384",
   "metadata": {},
   "source": [
    "Ensemble models seem to be the top performers, out of which Gradient Boosting is the best.\n",
    "\n",
    "Next, add standard scaling to numeric features and test again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "dd6f3d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/george/anaconda3/envs/ml-project-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "gb     0.863944\n",
       "svc    0.857938\n",
       "rf     0.854117\n",
       "lr     0.851059\n",
       "sgd    0.848329\n",
       "bg     0.847347\n",
       "rg     0.839048\n",
       "knn    0.832605\n",
       "dt     0.811422\n",
       "gnb         NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")), \n",
    "        (\"scaler\", StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")), \n",
    "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "        #(\"selector\", SelectPercentile(chi2, percentile=50)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_X = preprocessor.fit_transform(X_train_train)\n",
    "val_X = preprocessor.transform(X_train_val)\n",
    "train_y, val_y = y_train_train, y_train_val\n",
    "\n",
    "results = {}\n",
    "\n",
    "for algo, clf in algos.items():\n",
    "    try:\n",
    "        clf.fit(train_X, train_y)\n",
    "        score = clf.score(val_X, val_y)\n",
    "        results[algo] = score\n",
    "    except:\n",
    "        results[algo] = None\n",
    "\n",
    "pd.Series(results).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36fe192",
   "metadata": {},
   "source": [
    "The effect is negligible, so we'll skip standard scaling. Now use the Gradient Boosting algorithm to build the best model by fine tuning hyperparamters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "fd7b0064",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\"))\n",
    "    ]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")), \n",
    "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_X = preprocessor.fit_transform(X_train_train)\n",
    "val_X = preprocessor.transform(X_train_val)\n",
    "train_y, val_y = y_train_train, y_train_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "96046336",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "[CV] END learning_rate=0.1, loss=log_loss, max_depth=3, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=1000, subsample=0.9; total time=   4.1s\n",
      "[CV] END learning_rate=0.1, loss=log_loss, max_depth=3, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=1000, subsample=0.9; total time=   4.1s\n",
      "[CV] END learning_rate=0.1, loss=log_loss, max_depth=3, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=1000, subsample=0.9; total time=   4.2s\n",
      "[CV] END learning_rate=0.1, loss=log_loss, max_depth=3, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=1000, subsample=0.9; total time=   4.1s\n",
      "[CV] END learning_rate=0.1, loss=log_loss, max_depth=3, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=1000, subsample=0.9; total time=   4.1s\n",
      "[CV] END learning_rate=0.9, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=10, subsample=0.9; total time=   0.1s\n",
      "[CV] END learning_rate=0.9, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=10, subsample=0.9; total time=   0.1s\n",
      "[CV] END learning_rate=0.9, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=10, subsample=0.9; total time=   0.1s\n",
      "[CV] END learning_rate=0.9, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=10, subsample=0.9; total time=   0.1s\n",
      "[CV] END learning_rate=0.9, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=10, subsample=0.9; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, loss=log_loss, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=20, n_estimators=10, subsample=0.6; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=log_loss, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=20, n_estimators=10, subsample=0.6; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=log_loss, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=20, n_estimators=10, subsample=0.6; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=log_loss, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=20, n_estimators=10, subsample=0.6; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=log_loss, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=20, n_estimators=10, subsample=0.6; total time=   0.0s\n",
      "[CV] END learning_rate=0.9, loss=log_loss, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=10, subsample=0.6; total time=   0.0s\n",
      "[CV] END learning_rate=0.9, loss=log_loss, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=10, subsample=0.6; total time=   0.0s\n",
      "[CV] END learning_rate=0.9, loss=log_loss, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=10, subsample=0.6; total time=   0.0s\n",
      "[CV] END learning_rate=0.9, loss=log_loss, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=10, subsample=0.6; total time=   0.0s\n",
      "[CV] END learning_rate=0.9, loss=log_loss, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=10, subsample=0.6; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=3, min_samples_split=20, n_estimators=100, subsample=0.2; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=3, min_samples_split=20, n_estimators=100, subsample=0.2; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=3, min_samples_split=20, n_estimators=100, subsample=0.2; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=3, min_samples_split=20, n_estimators=100, subsample=0.2; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=3, min_samples_split=20, n_estimators=100, subsample=0.2; total time=   0.3s\n",
      "[CV] END learning_rate=0.9, loss=log_loss, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=10, subsample=0.9; total time=   0.0s\n",
      "[CV] END learning_rate=0.9, loss=log_loss, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=10, subsample=0.9; total time=   0.1s\n",
      "[CV] END learning_rate=0.9, loss=log_loss, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=10, subsample=0.9; total time=   0.1s\n",
      "[CV] END learning_rate=0.9, loss=log_loss, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=10, subsample=0.9; total time=   0.1s\n",
      "[CV] END learning_rate=0.9, loss=log_loss, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=10, subsample=0.9; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, loss=log_loss, max_depth=1, max_features=sqrt, min_samples_leaf=5, min_samples_split=4, n_estimators=1000, subsample=0.9; total time=   2.8s\n",
      "[CV] END learning_rate=0.01, loss=log_loss, max_depth=1, max_features=sqrt, min_samples_leaf=5, min_samples_split=4, n_estimators=1000, subsample=0.9; total time=   2.8s\n",
      "[CV] END learning_rate=0.01, loss=log_loss, max_depth=1, max_features=sqrt, min_samples_leaf=5, min_samples_split=4, n_estimators=1000, subsample=0.9; total time=   2.9s\n",
      "[CV] END learning_rate=0.01, loss=log_loss, max_depth=1, max_features=sqrt, min_samples_leaf=5, min_samples_split=4, n_estimators=1000, subsample=0.9; total time=   2.8s\n",
      "[CV] END learning_rate=0.01, loss=log_loss, max_depth=1, max_features=sqrt, min_samples_leaf=5, min_samples_split=4, n_estimators=1000, subsample=0.9; total time=   2.8s\n",
      "[CV] END learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=10, n_estimators=1000, subsample=0.9; total time=   5.5s\n",
      "[CV] END learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=10, n_estimators=1000, subsample=0.9; total time=   5.5s\n",
      "[CV] END learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=10, n_estimators=1000, subsample=0.9; total time=   5.6s\n",
      "[CV] END learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=10, n_estimators=1000, subsample=0.9; total time=   5.4s\n",
      "[CV] END learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=10, n_estimators=1000, subsample=0.9; total time=   5.5s\n",
      "[CV] END learning_rate=0.6, loss=log_loss, max_depth=3, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, n_estimators=100, subsample=0.9; total time=   0.4s\n",
      "[CV] END learning_rate=0.6, loss=log_loss, max_depth=3, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, n_estimators=100, subsample=0.9; total time=   0.4s\n",
      "[CV] END learning_rate=0.6, loss=log_loss, max_depth=3, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, n_estimators=100, subsample=0.9; total time=   0.4s\n",
      "[CV] END learning_rate=0.6, loss=log_loss, max_depth=3, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, n_estimators=100, subsample=0.9; total time=   0.4s\n",
      "[CV] END learning_rate=0.6, loss=log_loss, max_depth=3, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, n_estimators=100, subsample=0.9; total time=   0.4s\n",
      "[CV] END learning_rate=0.5, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=20, n_estimators=100, subsample=0.1; total time=   0.3s\n",
      "[CV] END learning_rate=0.5, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=20, n_estimators=100, subsample=0.1; total time=   0.3s\n",
      "[CV] END learning_rate=0.5, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=20, n_estimators=100, subsample=0.1; total time=   0.3s\n",
      "[CV] END learning_rate=0.5, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=20, n_estimators=100, subsample=0.1; total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.5, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=20, n_estimators=100, subsample=0.1; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=5, n_estimators=10, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=5, n_estimators=10, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=5, n_estimators=10, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=5, n_estimators=10, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=5, n_estimators=10, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.9, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=4, n_estimators=100, subsample=0.9; total time=   0.4s\n",
      "[CV] END learning_rate=0.9, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=4, n_estimators=100, subsample=0.9; total time=   0.4s\n",
      "[CV] END learning_rate=0.9, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=4, n_estimators=100, subsample=0.9; total time=   0.4s\n",
      "[CV] END learning_rate=0.9, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=4, n_estimators=100, subsample=0.9; total time=   0.4s\n",
      "[CV] END learning_rate=0.9, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=4, n_estimators=100, subsample=0.9; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=1000, subsample=0.8; total time=   3.3s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=1000, subsample=0.8; total time=   3.3s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=1000, subsample=0.8; total time=   3.4s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=1000, subsample=0.8; total time=   3.3s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=1000, subsample=0.8; total time=   3.3s\n",
      "[CV] END learning_rate=0.01, loss=log_loss, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=20, n_estimators=100, subsample=0.9; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=log_loss, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=20, n_estimators=100, subsample=0.9; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, loss=log_loss, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=20, n_estimators=100, subsample=0.9; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=log_loss, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=20, n_estimators=100, subsample=0.9; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, loss=log_loss, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=20, n_estimators=100, subsample=0.9; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=exponential, max_depth=1, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=1000, subsample=0.1; total time=   1.9s\n",
      "[CV] END learning_rate=0.001, loss=exponential, max_depth=1, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=1000, subsample=0.1; total time=   1.9s\n",
      "[CV] END learning_rate=0.001, loss=exponential, max_depth=1, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=1000, subsample=0.1; total time=   1.9s\n",
      "[CV] END learning_rate=0.001, loss=exponential, max_depth=1, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=1000, subsample=0.1; total time=   1.9s\n",
      "[CV] END learning_rate=0.001, loss=exponential, max_depth=1, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=1000, subsample=0.1; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=10, subsample=0.9; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=10, subsample=0.9; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=10, subsample=0.9; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=10, subsample=0.9; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=10, subsample=0.9; total time=   0.1s\n",
      "[CV] END learning_rate=0.9, loss=log_loss, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=4, n_estimators=10, subsample=0.2; total time=   0.0s\n",
      "[CV] END learning_rate=0.9, loss=log_loss, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=4, n_estimators=10, subsample=0.2; total time=   0.0s\n",
      "[CV] END learning_rate=0.9, loss=log_loss, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=4, n_estimators=10, subsample=0.2; total time=   0.0s\n",
      "[CV] END learning_rate=0.9, loss=log_loss, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=4, n_estimators=10, subsample=0.2; total time=   0.0s\n",
      "[CV] END learning_rate=0.9, loss=log_loss, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=4, n_estimators=10, subsample=0.2; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=20, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.1, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=20, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.1, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=20, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.1, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=20, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.1, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=20, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.5, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=10, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.5, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=10, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.5, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=10, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.5, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=10, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.5, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=10, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.5, loss=exponential, max_depth=1, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=10, subsample=0.9; total time=   0.0s\n",
      "[CV] END learning_rate=0.5, loss=exponential, max_depth=1, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=10, subsample=0.9; total time=   0.0s\n",
      "[CV] END learning_rate=0.5, loss=exponential, max_depth=1, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=10, subsample=0.9; total time=   0.0s\n",
      "[CV] END learning_rate=0.5, loss=exponential, max_depth=1, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=10, subsample=0.9; total time=   0.0s\n",
      "[CV] END learning_rate=0.5, loss=exponential, max_depth=1, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=10, subsample=0.9; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=1, max_features=log2, min_samples_leaf=3, min_samples_split=20, n_estimators=1000, subsample=0.5; total time=   2.6s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=1, max_features=log2, min_samples_leaf=3, min_samples_split=20, n_estimators=1000, subsample=0.5; total time=   2.6s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=1, max_features=log2, min_samples_leaf=3, min_samples_split=20, n_estimators=1000, subsample=0.5; total time=   2.7s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=1, max_features=log2, min_samples_leaf=3, min_samples_split=20, n_estimators=1000, subsample=0.5; total time=   2.6s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=1, max_features=log2, min_samples_leaf=3, min_samples_split=20, n_estimators=1000, subsample=0.5; total time=   2.6s\n",
      "[CV] END learning_rate=0.1, loss=log_loss, max_depth=1, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=log_loss, max_depth=1, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=log_loss, max_depth=1, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=log_loss, max_depth=1, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=log_loss, max_depth=1, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.5, loss=log_loss, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=100, subsample=0.2; total time=   0.3s\n",
      "[CV] END learning_rate=0.5, loss=log_loss, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=100, subsample=0.2; total time=   0.3s\n",
      "[CV] END learning_rate=0.5, loss=log_loss, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=100, subsample=0.2; total time=   0.3s\n",
      "[CV] END learning_rate=0.5, loss=log_loss, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=100, subsample=0.2; total time=   0.3s\n",
      "[CV] END learning_rate=0.5, loss=log_loss, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=100, subsample=0.2; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END learning_rate=0.9, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=1000, subsample=0.6; total time=   4.1s\n",
      "[CV] END learning_rate=0.9, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=1000, subsample=0.6; total time=   4.1s\n",
      "[CV] END learning_rate=0.9, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=1000, subsample=0.6; total time=   4.3s\n",
      "[CV] END learning_rate=0.9, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=1000, subsample=0.6; total time=   4.2s\n",
      "[CV] END learning_rate=0.9, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=1000, subsample=0.6; total time=   4.2s\n",
      "[CV] END learning_rate=0.1, loss=exponential, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.1; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, loss=exponential, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.1; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, loss=exponential, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.1; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, loss=exponential, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.1; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, loss=exponential, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.1; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=20, n_estimators=10, subsample=0.9; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=20, n_estimators=10, subsample=0.9; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=20, n_estimators=10, subsample=0.9; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=20, n_estimators=10, subsample=0.9; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=20, n_estimators=10, subsample=0.9; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, loss=exponential, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100, subsample=0.1; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, loss=exponential, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100, subsample=0.1; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, loss=exponential, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100, subsample=0.1; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, loss=exponential, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100, subsample=0.1; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, loss=exponential, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100, subsample=0.1; total time=   0.2s\n",
      "[CV] END learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=2, n_estimators=1000, subsample=0.1; total time=   3.1s\n",
      "[CV] END learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=2, n_estimators=1000, subsample=0.1; total time=   3.0s\n",
      "[CV] END learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=2, n_estimators=1000, subsample=0.1; total time=   3.0s\n",
      "[CV] END learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=2, n_estimators=1000, subsample=0.1; total time=   3.0s\n",
      "[CV] END learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=2, n_estimators=1000, subsample=0.1; total time=   3.0s\n",
      "[CV] END learning_rate=0.5, loss=log_loss, max_depth=3, max_features=sqrt, min_samples_leaf=5, min_samples_split=20, n_estimators=100, subsample=0.6; total time=   0.4s\n",
      "[CV] END learning_rate=0.5, loss=log_loss, max_depth=3, max_features=sqrt, min_samples_leaf=5, min_samples_split=20, n_estimators=100, subsample=0.6; total time=   0.4s\n",
      "[CV] END learning_rate=0.5, loss=log_loss, max_depth=3, max_features=sqrt, min_samples_leaf=5, min_samples_split=20, n_estimators=100, subsample=0.6; total time=   0.4s\n",
      "[CV] END learning_rate=0.5, loss=log_loss, max_depth=3, max_features=sqrt, min_samples_leaf=5, min_samples_split=20, n_estimators=100, subsample=0.6; total time=   0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.5, loss=log_loss, max_depth=3, max_features=sqrt, min_samples_leaf=5, min_samples_split=20, n_estimators=100, subsample=0.6; total time=   0.4s\n",
      "[CV] END learning_rate=0.6, loss=log_loss, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=2, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.6, loss=log_loss, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=2, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.6, loss=log_loss, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=2, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.6, loss=log_loss, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=2, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.6, loss=log_loss, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=2, n_estimators=100, subsample=0.8; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=20, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=20, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=20, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=20, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=20, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END learning_rate=0.5, loss=log_loss, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=10, subsample=0.6; total time=   0.1s\n",
      "[CV] END learning_rate=0.5, loss=log_loss, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=10, subsample=0.6; total time=   0.1s\n",
      "[CV] END learning_rate=0.5, loss=log_loss, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=10, subsample=0.6; total time=   0.1s\n",
      "[CV] END learning_rate=0.5, loss=log_loss, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=10, subsample=0.6; total time=   0.1s\n",
      "[CV] END learning_rate=0.5, loss=log_loss, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=10, subsample=0.6; total time=   0.1s\n",
      "[CV] END learning_rate=0.5, loss=exponential, max_depth=1, max_features=log2, min_samples_leaf=1, min_samples_split=20, n_estimators=10, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.5, loss=exponential, max_depth=1, max_features=log2, min_samples_leaf=1, min_samples_split=20, n_estimators=10, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.5, loss=exponential, max_depth=1, max_features=log2, min_samples_leaf=1, min_samples_split=20, n_estimators=10, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.5, loss=exponential, max_depth=1, max_features=log2, min_samples_leaf=1, min_samples_split=20, n_estimators=10, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.5, loss=exponential, max_depth=1, max_features=log2, min_samples_leaf=1, min_samples_split=20, n_estimators=10, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=log_loss, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=10, subsample=0.6; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=log_loss, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=10, subsample=0.6; total time=   0.1s\n",
      "[CV] END learning_rate=0.001, loss=log_loss, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=10, subsample=0.6; total time=   0.1s\n",
      "[CV] END learning_rate=0.001, loss=log_loss, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=10, subsample=0.6; total time=   0.1s\n",
      "[CV] END learning_rate=0.001, loss=log_loss, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=10, subsample=0.6; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, loss=log_loss, max_depth=3, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=100, subsample=0.9; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=log_loss, max_depth=3, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=100, subsample=0.9; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=log_loss, max_depth=3, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=100, subsample=0.9; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=log_loss, max_depth=3, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=100, subsample=0.9; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=log_loss, max_depth=3, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=100, subsample=0.9; total time=   0.4s\n",
      "[CV] END learning_rate=0.5, loss=log_loss, max_depth=1, max_features=sqrt, min_samples_leaf=5, min_samples_split=20, n_estimators=1000, subsample=0.9; total time=   2.8s\n",
      "[CV] END learning_rate=0.5, loss=log_loss, max_depth=1, max_features=sqrt, min_samples_leaf=5, min_samples_split=20, n_estimators=1000, subsample=0.9; total time=   2.7s\n",
      "[CV] END learning_rate=0.5, loss=log_loss, max_depth=1, max_features=sqrt, min_samples_leaf=5, min_samples_split=20, n_estimators=1000, subsample=0.9; total time=   2.8s\n",
      "[CV] END learning_rate=0.5, loss=log_loss, max_depth=1, max_features=sqrt, min_samples_leaf=5, min_samples_split=20, n_estimators=1000, subsample=0.9; total time=   2.7s\n",
      "[CV] END learning_rate=0.5, loss=log_loss, max_depth=1, max_features=sqrt, min_samples_leaf=5, min_samples_split=20, n_estimators=1000, subsample=0.9; total time=   2.8s\n",
      "[CV] END learning_rate=0.5, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=3, n_estimators=1000, subsample=0.5; total time=   4.1s\n",
      "[CV] END learning_rate=0.5, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=3, n_estimators=1000, subsample=0.5; total time=   4.1s\n",
      "[CV] END learning_rate=0.5, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=3, n_estimators=1000, subsample=0.5; total time=   4.2s\n",
      "[CV] END learning_rate=0.5, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=3, n_estimators=1000, subsample=0.5; total time=   4.1s\n",
      "[CV] END learning_rate=0.5, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=3, n_estimators=1000, subsample=0.5; total time=   4.2s\n",
      "[CV] END learning_rate=0.1, loss=log_loss, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.1, loss=log_loss, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.1, loss=log_loss, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.1, loss=log_loss, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.1, loss=log_loss, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.5, loss=exponential, max_depth=1, max_features=log2, min_samples_leaf=1, min_samples_split=20, n_estimators=10, subsample=0.2; total time=   0.0s\n",
      "[CV] END learning_rate=0.5, loss=exponential, max_depth=1, max_features=log2, min_samples_leaf=1, min_samples_split=20, n_estimators=10, subsample=0.2; total time=   0.0s\n",
      "[CV] END learning_rate=0.5, loss=exponential, max_depth=1, max_features=log2, min_samples_leaf=1, min_samples_split=20, n_estimators=10, subsample=0.2; total time=   0.0s\n",
      "[CV] END learning_rate=0.5, loss=exponential, max_depth=1, max_features=log2, min_samples_leaf=1, min_samples_split=20, n_estimators=10, subsample=0.2; total time=   0.0s\n",
      "[CV] END learning_rate=0.5, loss=exponential, max_depth=1, max_features=log2, min_samples_leaf=1, min_samples_split=20, n_estimators=10, subsample=0.2; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=10, subsample=0.1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END learning_rate=0.6, loss=log_loss, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.6, loss=log_loss, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.6, loss=log_loss, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.6, loss=log_loss, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.6, loss=log_loss, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.9, loss=exponential, max_depth=1, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.9, loss=exponential, max_depth=1, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.9, loss=exponential, max_depth=1, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.9, loss=exponential, max_depth=1, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.9, loss=exponential, max_depth=1, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=4, n_estimators=10, subsample=0.6; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=4, n_estimators=10, subsample=0.6; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=4, n_estimators=10, subsample=0.6; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=4, n_estimators=10, subsample=0.6; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=4, n_estimators=10, subsample=0.6; total time=   0.1s\n",
      "[CV] END learning_rate=0.9, loss=exponential, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=3, n_estimators=100, subsample=0.9; total time=   0.3s\n",
      "[CV] END learning_rate=0.9, loss=exponential, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=3, n_estimators=100, subsample=0.9; total time=   0.3s\n",
      "[CV] END learning_rate=0.9, loss=exponential, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=3, n_estimators=100, subsample=0.9; total time=   0.3s\n",
      "[CV] END learning_rate=0.9, loss=exponential, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=3, n_estimators=100, subsample=0.9; total time=   0.3s\n",
      "[CV] END learning_rate=0.9, loss=exponential, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=3, n_estimators=100, subsample=0.9; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=20, n_estimators=100, subsample=0.9; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=20, n_estimators=100, subsample=0.9; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=20, n_estimators=100, subsample=0.9; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=20, n_estimators=100, subsample=0.9; total time=   0.6s\n",
      "[CV] END learning_rate=0.1, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=20, n_estimators=100, subsample=0.9; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=3, min_samples_split=10, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=3, min_samples_split=10, n_estimators=100, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=3, min_samples_split=10, n_estimators=100, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=3, min_samples_split=10, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=3, min_samples_split=10, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.5, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=20, n_estimators=1000, subsample=0.2; total time=   3.3s\n",
      "[CV] END learning_rate=0.5, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=20, n_estimators=1000, subsample=0.2; total time=   3.3s\n",
      "[CV] END learning_rate=0.5, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=20, n_estimators=1000, subsample=0.2; total time=   3.3s\n",
      "[CV] END learning_rate=0.5, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=20, n_estimators=1000, subsample=0.2; total time=   3.3s\n",
      "[CV] END learning_rate=0.5, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=20, n_estimators=1000, subsample=0.2; total time=   3.2s\n",
      "[CV] END learning_rate=0.001, loss=log_loss, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=10, subsample=0.2; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=log_loss, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=10, subsample=0.2; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=log_loss, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=10, subsample=0.2; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=log_loss, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=10, subsample=0.2; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=log_loss, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=10, subsample=0.2; total time=   0.0s\n",
      "[CV] END learning_rate=0.6, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=5, min_samples_split=2, n_estimators=10, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.6, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=5, min_samples_split=2, n_estimators=10, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.6, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=5, min_samples_split=2, n_estimators=10, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.6, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=5, min_samples_split=2, n_estimators=10, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.6, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=5, min_samples_split=2, n_estimators=10, subsample=0.5; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.001, loss=exponential, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=1000, subsample=0.9; total time=   2.9s\n",
      "[CV] END learning_rate=0.001, loss=exponential, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=1000, subsample=0.9; total time=   2.9s\n",
      "[CV] END learning_rate=0.001, loss=exponential, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=1000, subsample=0.9; total time=   3.0s\n",
      "[CV] END learning_rate=0.001, loss=exponential, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=1000, subsample=0.9; total time=   2.9s\n",
      "[CV] END learning_rate=0.001, loss=exponential, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=1000, subsample=0.9; total time=   2.9s\n",
      "[CV] END learning_rate=0.01, loss=log_loss, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=0.9; total time=   3.5s\n",
      "[CV] END learning_rate=0.01, loss=log_loss, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=0.9; total time=   3.5s\n",
      "[CV] END learning_rate=0.01, loss=log_loss, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=0.9; total time=   3.6s\n",
      "[CV] END learning_rate=0.01, loss=log_loss, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=0.9; total time=   3.5s\n",
      "[CV] END learning_rate=0.01, loss=log_loss, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=0.9; total time=   3.5s\n",
      "[CV] END learning_rate=0.5, loss=log_loss, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.5, loss=log_loss, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.5, loss=log_loss, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.5, loss=log_loss, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.5, loss=log_loss, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, loss=exponential, max_depth=1, max_features=log2, min_samples_leaf=2, min_samples_split=3, n_estimators=1000, subsample=0.8; total time=   2.5s\n",
      "[CV] END learning_rate=0.1, loss=exponential, max_depth=1, max_features=log2, min_samples_leaf=2, min_samples_split=3, n_estimators=1000, subsample=0.8; total time=   2.5s\n",
      "[CV] END learning_rate=0.1, loss=exponential, max_depth=1, max_features=log2, min_samples_leaf=2, min_samples_split=3, n_estimators=1000, subsample=0.8; total time=   2.5s\n",
      "[CV] END learning_rate=0.1, loss=exponential, max_depth=1, max_features=log2, min_samples_leaf=2, min_samples_split=3, n_estimators=1000, subsample=0.8; total time=   2.5s\n",
      "[CV] END learning_rate=0.1, loss=exponential, max_depth=1, max_features=log2, min_samples_leaf=2, min_samples_split=3, n_estimators=1000, subsample=0.8; total time=   2.5s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=6, n_estimators=10, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=6, n_estimators=10, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=6, n_estimators=10, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=6, n_estimators=10, subsample=0.5; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=6, n_estimators=10, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=1, max_features=sqrt, min_samples_leaf=5, min_samples_split=20, n_estimators=1000, subsample=0.9; total time=   2.5s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=1, max_features=sqrt, min_samples_leaf=5, min_samples_split=20, n_estimators=1000, subsample=0.9; total time=   2.5s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=1, max_features=sqrt, min_samples_leaf=5, min_samples_split=20, n_estimators=1000, subsample=0.9; total time=   2.5s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=1, max_features=sqrt, min_samples_leaf=5, min_samples_split=20, n_estimators=1000, subsample=0.9; total time=   2.5s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=1, max_features=sqrt, min_samples_leaf=5, min_samples_split=20, n_estimators=1000, subsample=0.9; total time=   2.5s\n",
      "[CV] END learning_rate=0.1, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=1000, subsample=0.1; total time=   2.2s\n",
      "[CV] END learning_rate=0.1, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=1000, subsample=0.1; total time=   2.2s\n",
      "[CV] END learning_rate=0.1, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=1000, subsample=0.1; total time=   2.2s\n",
      "[CV] END learning_rate=0.1, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=1000, subsample=0.1; total time=   2.2s\n",
      "[CV] END learning_rate=0.1, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=1000, subsample=0.1; total time=   2.2s\n",
      "[CV] END learning_rate=0.1, loss=log_loss, max_depth=3, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.1; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=log_loss, max_depth=3, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.1; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=log_loss, max_depth=3, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.1; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=log_loss, max_depth=3, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.1; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=log_loss, max_depth=3, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.1; total time=   0.3s\n",
      "[CV] END learning_rate=0.5, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1000, subsample=0.8; total time=   6.1s\n",
      "[CV] END learning_rate=0.5, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1000, subsample=0.8; total time=   6.1s\n",
      "[CV] END learning_rate=0.5, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1000, subsample=0.8; total time=   5.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.5, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1000, subsample=0.8; total time=   6.0s\n",
      "[CV] END learning_rate=0.5, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1000, subsample=0.8; total time=   6.5s\n",
      "[CV] END learning_rate=0.1, loss=log_loss, max_depth=1, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=10, subsample=0.2; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, loss=log_loss, max_depth=1, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=10, subsample=0.2; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, loss=log_loss, max_depth=1, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=10, subsample=0.2; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, loss=log_loss, max_depth=1, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=10, subsample=0.2; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, loss=log_loss, max_depth=1, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=10, subsample=0.2; total time=   0.0s\n",
      "[CV] END learning_rate=0.5, loss=log_loss, max_depth=3, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=10, subsample=0.2; total time=   0.0s\n",
      "[CV] END learning_rate=0.5, loss=log_loss, max_depth=3, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=10, subsample=0.2; total time=   0.0s\n",
      "[CV] END learning_rate=0.5, loss=log_loss, max_depth=3, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=10, subsample=0.2; total time=   0.0s\n",
      "[CV] END learning_rate=0.5, loss=log_loss, max_depth=3, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=10, subsample=0.2; total time=   0.0s\n",
      "[CV] END learning_rate=0.5, loss=log_loss, max_depth=3, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=10, subsample=0.2; total time=   0.0s\n",
      "[CV] END learning_rate=0.5, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=10, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.5, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=10, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.5, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=10, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.5, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=10, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.5, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=10, subsample=0.5; total time=   0.1s\n",
      "[CV] END learning_rate=0.001, loss=log_loss, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=100, subsample=0.1; total time=   0.2s\n",
      "[CV] END learning_rate=0.001, loss=log_loss, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=100, subsample=0.1; total time=   0.2s\n",
      "[CV] END learning_rate=0.001, loss=log_loss, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=100, subsample=0.1; total time=   0.2s\n",
      "[CV] END learning_rate=0.001, loss=log_loss, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=100, subsample=0.1; total time=   0.2s\n",
      "[CV] END learning_rate=0.001, loss=log_loss, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=100, subsample=0.1; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, loss=log_loss, max_depth=1, max_features=sqrt, min_samples_leaf=1, min_samples_split=20, n_estimators=1000, subsample=0.8; total time=   2.8s\n",
      "[CV] END learning_rate=0.1, loss=log_loss, max_depth=1, max_features=sqrt, min_samples_leaf=1, min_samples_split=20, n_estimators=1000, subsample=0.8; total time=   2.9s\n",
      "[CV] END learning_rate=0.1, loss=log_loss, max_depth=1, max_features=sqrt, min_samples_leaf=1, min_samples_split=20, n_estimators=1000, subsample=0.8; total time=   2.9s\n",
      "[CV] END learning_rate=0.1, loss=log_loss, max_depth=1, max_features=sqrt, min_samples_leaf=1, min_samples_split=20, n_estimators=1000, subsample=0.8; total time=   2.9s\n",
      "[CV] END learning_rate=0.1, loss=log_loss, max_depth=1, max_features=sqrt, min_samples_leaf=1, min_samples_split=20, n_estimators=1000, subsample=0.8; total time=   2.9s\n",
      "[CV] END learning_rate=0.01, loss=log_loss, max_depth=1, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, n_estimators=1000, subsample=0.2; total time=   2.5s\n",
      "[CV] END learning_rate=0.01, loss=log_loss, max_depth=1, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, n_estimators=1000, subsample=0.2; total time=   2.5s\n",
      "[CV] END learning_rate=0.01, loss=log_loss, max_depth=1, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, n_estimators=1000, subsample=0.2; total time=   2.5s\n",
      "[CV] END learning_rate=0.01, loss=log_loss, max_depth=1, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, n_estimators=1000, subsample=0.2; total time=   2.5s\n",
      "[CV] END learning_rate=0.01, loss=log_loss, max_depth=1, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, n_estimators=1000, subsample=0.2; total time=   2.5s\n",
      "[CV] END learning_rate=0.01, loss=log_loss, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=log_loss, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=log_loss, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=log_loss, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=log_loss, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END learning_rate=0.6, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=100, subsample=0.1; total time=   0.3s\n",
      "[CV] END learning_rate=0.6, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=100, subsample=0.1; total time=   0.3s\n",
      "[CV] END learning_rate=0.6, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=100, subsample=0.1; total time=   0.3s\n",
      "[CV] END learning_rate=0.6, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=100, subsample=0.1; total time=   0.3s\n",
      "[CV] END learning_rate=0.6, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=100, subsample=0.1; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=log_loss, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=100, subsample=0.1; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=log_loss, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=100, subsample=0.1; total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, loss=log_loss, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=100, subsample=0.1; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=log_loss, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=100, subsample=0.1; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=log_loss, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=100, subsample=0.1; total time=   0.3s\n",
      "[CV] END learning_rate=0.9, loss=log_loss, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=10, n_estimators=1000, subsample=0.2; total time=   3.8s\n",
      "[CV] END learning_rate=0.9, loss=log_loss, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=10, n_estimators=1000, subsample=0.2; total time=   3.9s\n",
      "[CV] END learning_rate=0.9, loss=log_loss, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=10, n_estimators=1000, subsample=0.2; total time=   3.6s\n",
      "[CV] END learning_rate=0.9, loss=log_loss, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=10, n_estimators=1000, subsample=0.2; total time=   3.7s\n",
      "[CV] END learning_rate=0.9, loss=log_loss, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=10, n_estimators=1000, subsample=0.2; total time=   3.7s\n",
      "[CV] END learning_rate=0.001, loss=log_loss, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=10, subsample=0.2; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=log_loss, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=10, subsample=0.2; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=log_loss, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=10, subsample=0.2; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=log_loss, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=10, subsample=0.2; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=log_loss, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=10, subsample=0.2; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=100, subsample=0.6; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=100, subsample=0.6; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=100, subsample=0.6; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=100, subsample=0.6; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=100, subsample=0.6; total time=   0.5s\n",
      "[CV] END learning_rate=0.9, loss=log_loss, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=20, n_estimators=10, subsample=0.6; total time=   0.0s\n",
      "[CV] END learning_rate=0.9, loss=log_loss, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=20, n_estimators=10, subsample=0.6; total time=   0.0s\n",
      "[CV] END learning_rate=0.9, loss=log_loss, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=20, n_estimators=10, subsample=0.6; total time=   0.0s\n",
      "[CV] END learning_rate=0.9, loss=log_loss, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=20, n_estimators=10, subsample=0.6; total time=   0.0s\n",
      "[CV] END learning_rate=0.9, loss=log_loss, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=20, n_estimators=10, subsample=0.6; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, loss=log_loss, max_depth=4, max_features=log2, min_samples_leaf=5, min_samples_split=4, n_estimators=100, subsample=0.2; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=log_loss, max_depth=4, max_features=log2, min_samples_leaf=5, min_samples_split=4, n_estimators=100, subsample=0.2; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=log_loss, max_depth=4, max_features=log2, min_samples_leaf=5, min_samples_split=4, n_estimators=100, subsample=0.2; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=log_loss, max_depth=4, max_features=log2, min_samples_leaf=5, min_samples_split=4, n_estimators=100, subsample=0.2; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=log_loss, max_depth=4, max_features=log2, min_samples_leaf=5, min_samples_split=4, n_estimators=100, subsample=0.2; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=20, n_estimators=100, subsample=0.6; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=20, n_estimators=100, subsample=0.6; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=20, n_estimators=100, subsample=0.6; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=20, n_estimators=100, subsample=0.6; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=20, n_estimators=100, subsample=0.6; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=1000, subsample=0.5; total time=   3.5s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=1000, subsample=0.5; total time=   3.5s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=1000, subsample=0.5; total time=   3.6s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=1000, subsample=0.5; total time=   3.6s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=1000, subsample=0.5; total time=   3.6s\n",
      "[CV] END learning_rate=0.6, loss=exponential, max_depth=1, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1000, subsample=0.2; total time=   2.2s\n",
      "[CV] END learning_rate=0.6, loss=exponential, max_depth=1, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1000, subsample=0.2; total time=   2.1s\n",
      "[CV] END learning_rate=0.6, loss=exponential, max_depth=1, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1000, subsample=0.2; total time=   2.2s\n",
      "[CV] END learning_rate=0.6, loss=exponential, max_depth=1, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1000, subsample=0.2; total time=   2.1s\n",
      "[CV] END learning_rate=0.6, loss=exponential, max_depth=1, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1000, subsample=0.2; total time=   2.1s\n",
      "[CV] END learning_rate=0.6, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=100, subsample=0.9; total time=   0.5s\n",
      "[CV] END learning_rate=0.6, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=100, subsample=0.9; total time=   0.5s\n",
      "[CV] END learning_rate=0.6, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=100, subsample=0.9; total time=   0.5s\n",
      "[CV] END learning_rate=0.6, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=100, subsample=0.9; total time=   0.5s\n",
      "[CV] END learning_rate=0.6, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=100, subsample=0.9; total time=   0.5s\n",
      "[CV] END learning_rate=0.5, loss=exponential, max_depth=1, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=0.9; total time=   2.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.5, loss=exponential, max_depth=1, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=0.9; total time=   2.5s\n",
      "[CV] END learning_rate=0.5, loss=exponential, max_depth=1, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=0.9; total time=   2.5s\n",
      "[CV] END learning_rate=0.5, loss=exponential, max_depth=1, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=0.9; total time=   2.4s\n",
      "[CV] END learning_rate=0.5, loss=exponential, max_depth=1, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=0.9; total time=   2.4s\n",
      "[CV] END learning_rate=0.9, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=10, subsample=0.8; total time=   0.1s\n",
      "[CV] END learning_rate=0.9, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=10, subsample=0.8; total time=   0.1s\n",
      "[CV] END learning_rate=0.9, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=10, subsample=0.8; total time=   0.1s\n",
      "[CV] END learning_rate=0.9, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=10, subsample=0.8; total time=   0.0s\n",
      "[CV] END learning_rate=0.9, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=10, subsample=0.8; total time=   0.1s\n",
      "[CV] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=2, n_estimators=1000, subsample=0.8; total time=   6.6s\n",
      "[CV] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=2, n_estimators=1000, subsample=0.8; total time=   6.7s\n",
      "[CV] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=2, n_estimators=1000, subsample=0.8; total time=   6.8s\n",
      "[CV] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=2, n_estimators=1000, subsample=0.8; total time=   6.7s\n",
      "[CV] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=2, n_estimators=1000, subsample=0.8; total time=   6.7s\n",
      "[CV] END learning_rate=0.1, loss=log_loss, max_depth=3, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=log_loss, max_depth=3, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=log_loss, max_depth=3, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=log_loss, max_depth=3, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=log_loss, max_depth=3, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=1000, subsample=0.5; total time=   3.6s\n",
      "[CV] END learning_rate=0.001, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=1000, subsample=0.5; total time=   3.6s\n",
      "[CV] END learning_rate=0.001, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=1000, subsample=0.5; total time=   3.7s\n",
      "[CV] END learning_rate=0.001, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=1000, subsample=0.5; total time=   3.6s\n",
      "[CV] END learning_rate=0.001, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=1000, subsample=0.5; total time=   3.6s\n",
      "[CV] END learning_rate=0.1, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END learning_rate=0.1, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END learning_rate=0.6, loss=log_loss, max_depth=1, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=10, subsample=0.2; total time=   0.0s\n",
      "[CV] END learning_rate=0.6, loss=log_loss, max_depth=1, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=10, subsample=0.2; total time=   0.0s\n",
      "[CV] END learning_rate=0.6, loss=log_loss, max_depth=1, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=10, subsample=0.2; total time=   0.0s\n",
      "[CV] END learning_rate=0.6, loss=log_loss, max_depth=1, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=10, subsample=0.2; total time=   0.0s\n",
      "[CV] END learning_rate=0.6, loss=log_loss, max_depth=1, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=10, subsample=0.2; total time=   0.0s\n",
      "[CV] END learning_rate=0.9, loss=log_loss, max_depth=1, max_features=sqrt, min_samples_leaf=3, min_samples_split=20, n_estimators=10, subsample=0.9; total time=   0.0s\n",
      "[CV] END learning_rate=0.9, loss=log_loss, max_depth=1, max_features=sqrt, min_samples_leaf=3, min_samples_split=20, n_estimators=10, subsample=0.9; total time=   0.0s\n",
      "[CV] END learning_rate=0.9, loss=log_loss, max_depth=1, max_features=sqrt, min_samples_leaf=3, min_samples_split=20, n_estimators=10, subsample=0.9; total time=   0.0s\n",
      "[CV] END learning_rate=0.9, loss=log_loss, max_depth=1, max_features=sqrt, min_samples_leaf=3, min_samples_split=20, n_estimators=10, subsample=0.9; total time=   0.0s\n",
      "[CV] END learning_rate=0.9, loss=log_loss, max_depth=1, max_features=sqrt, min_samples_leaf=3, min_samples_split=20, n_estimators=10, subsample=0.9; total time=   0.0s\n",
      "[CV] END learning_rate=0.5, loss=exponential, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=10, n_estimators=1000, subsample=0.9; total time=   2.8s\n",
      "[CV] END learning_rate=0.5, loss=exponential, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=10, n_estimators=1000, subsample=0.9; total time=   2.8s\n",
      "[CV] END learning_rate=0.5, loss=exponential, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=10, n_estimators=1000, subsample=0.9; total time=   2.8s\n",
      "[CV] END learning_rate=0.5, loss=exponential, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=10, n_estimators=1000, subsample=0.9; total time=   2.8s\n",
      "[CV] END learning_rate=0.5, loss=exponential, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=10, n_estimators=1000, subsample=0.9; total time=   2.8s\n",
      "[CV] END learning_rate=0.1, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=5, min_samples_split=5, n_estimators=100, subsample=0.6; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=5, min_samples_split=5, n_estimators=100, subsample=0.6; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=5, min_samples_split=5, n_estimators=100, subsample=0.6; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=5, min_samples_split=5, n_estimators=100, subsample=0.6; total time=   0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.1, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=5, min_samples_split=5, n_estimators=100, subsample=0.6; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=exponential, max_depth=1, max_features=log2, min_samples_leaf=2, min_samples_split=4, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, loss=exponential, max_depth=1, max_features=log2, min_samples_leaf=2, min_samples_split=4, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, loss=exponential, max_depth=1, max_features=log2, min_samples_leaf=2, min_samples_split=4, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, loss=exponential, max_depth=1, max_features=log2, min_samples_leaf=2, min_samples_split=4, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, loss=exponential, max_depth=1, max_features=log2, min_samples_leaf=2, min_samples_split=4, n_estimators=100, subsample=0.8; total time=   0.3s\n",
      "[CV] END learning_rate=0.6, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=3, n_estimators=10, subsample=0.2; total time=   0.0s\n",
      "[CV] END learning_rate=0.6, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=3, n_estimators=10, subsample=0.2; total time=   0.0s\n",
      "[CV] END learning_rate=0.6, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=3, n_estimators=10, subsample=0.2; total time=   0.0s\n",
      "[CV] END learning_rate=0.6, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=3, n_estimators=10, subsample=0.2; total time=   0.0s\n",
      "[CV] END learning_rate=0.6, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=3, n_estimators=10, subsample=0.2; total time=   0.0s\n",
      "[CV] END learning_rate=0.5, loss=exponential, max_depth=2, max_features=log2, min_samples_leaf=2, min_samples_split=20, n_estimators=100, subsample=0.1; total time=   0.2s\n",
      "[CV] END learning_rate=0.5, loss=exponential, max_depth=2, max_features=log2, min_samples_leaf=2, min_samples_split=20, n_estimators=100, subsample=0.1; total time=   0.2s\n",
      "[CV] END learning_rate=0.5, loss=exponential, max_depth=2, max_features=log2, min_samples_leaf=2, min_samples_split=20, n_estimators=100, subsample=0.1; total time=   0.2s\n",
      "[CV] END learning_rate=0.5, loss=exponential, max_depth=2, max_features=log2, min_samples_leaf=2, min_samples_split=20, n_estimators=100, subsample=0.1; total time=   0.2s\n",
      "[CV] END learning_rate=0.5, loss=exponential, max_depth=2, max_features=log2, min_samples_leaf=2, min_samples_split=20, n_estimators=100, subsample=0.1; total time=   0.2s\n",
      "[CV] END learning_rate=0.001, loss=log_loss, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=20, n_estimators=1000, subsample=0.5; total time=   3.6s\n",
      "[CV] END learning_rate=0.001, loss=log_loss, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=20, n_estimators=1000, subsample=0.5; total time=   3.6s\n",
      "[CV] END learning_rate=0.001, loss=log_loss, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=20, n_estimators=1000, subsample=0.5; total time=   3.6s\n",
      "[CV] END learning_rate=0.001, loss=log_loss, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=20, n_estimators=1000, subsample=0.5; total time=   3.6s\n",
      "[CV] END learning_rate=0.001, loss=log_loss, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=20, n_estimators=1000, subsample=0.5; total time=   3.6s\n",
      "[CV] END learning_rate=0.1, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=0.9; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=0.9; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=0.9; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=0.9; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=0.9; total time=   0.4s\n",
      "[CV] END learning_rate=0.5, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1000, subsample=0.9; total time=   6.3s\n",
      "[CV] END learning_rate=0.5, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1000, subsample=0.9; total time=   6.4s\n",
      "[CV] END learning_rate=0.5, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1000, subsample=0.9; total time=   6.7s\n",
      "[CV] END learning_rate=0.5, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1000, subsample=0.9; total time=   6.5s\n",
      "[CV] END learning_rate=0.5, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1000, subsample=0.9; total time=   6.4s\n",
      "[CV] END learning_rate=0.001, loss=log_loss, max_depth=3, max_features=log2, min_samples_leaf=2, min_samples_split=20, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=log_loss, max_depth=3, max_features=log2, min_samples_leaf=2, min_samples_split=20, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=log_loss, max_depth=3, max_features=log2, min_samples_leaf=2, min_samples_split=20, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=log_loss, max_depth=3, max_features=log2, min_samples_leaf=2, min_samples_split=20, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.001, loss=log_loss, max_depth=3, max_features=log2, min_samples_leaf=2, min_samples_split=20, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.1, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=10, subsample=0.9; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=10, subsample=0.9; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=10, subsample=0.9; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=10, subsample=0.9; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=10, subsample=0.9; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=1000, subsample=0.8; total time=   4.0s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=1000, subsample=0.8; total time=   4.1s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=1000, subsample=0.8; total time=   4.3s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=1000, subsample=0.8; total time=   4.0s\n",
      "[CV] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=1000, subsample=0.8; total time=   4.1s\n",
      "[CV] END learning_rate=0.5, loss=log_loss, max_depth=1, max_features=sqrt, min_samples_leaf=3, min_samples_split=20, n_estimators=10, subsample=0.2; total time=   0.0s\n",
      "[CV] END learning_rate=0.5, loss=log_loss, max_depth=1, max_features=sqrt, min_samples_leaf=3, min_samples_split=20, n_estimators=10, subsample=0.2; total time=   0.0s\n",
      "[CV] END learning_rate=0.5, loss=log_loss, max_depth=1, max_features=sqrt, min_samples_leaf=3, min_samples_split=20, n_estimators=10, subsample=0.2; total time=   0.0s\n",
      "[CV] END learning_rate=0.5, loss=log_loss, max_depth=1, max_features=sqrt, min_samples_leaf=3, min_samples_split=20, n_estimators=10, subsample=0.2; total time=   0.0s\n",
      "[CV] END learning_rate=0.5, loss=log_loss, max_depth=1, max_features=sqrt, min_samples_leaf=3, min_samples_split=20, n_estimators=10, subsample=0.2; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.6, loss=log_loss, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=1000, subsample=0.2; total time=   3.3s\n",
      "[CV] END learning_rate=0.6, loss=log_loss, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=1000, subsample=0.2; total time=   3.4s\n",
      "[CV] END learning_rate=0.6, loss=log_loss, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=1000, subsample=0.2; total time=   3.3s\n",
      "[CV] END learning_rate=0.6, loss=log_loss, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=1000, subsample=0.2; total time=   3.4s\n",
      "[CV] END learning_rate=0.6, loss=log_loss, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=1000, subsample=0.2; total time=   3.4s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=GradientBoostingClassifier(), n_iter=100,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: [0.001, 0.01, 0.1, 0.5,\n",
       "                                                          0.6, 0.9],\n",
       "                                        &#x27;loss&#x27;: [&#x27;log_loss&#x27;, &#x27;exponential&#x27;],\n",
       "                                        &#x27;max_depth&#x27;: [1, 2, 3, 4, 5],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 3, 5],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 3, 4, 5, 6, 10,\n",
       "                                                              20],\n",
       "                                        &#x27;n_estimators&#x27;: [10, 100, 1000],\n",
       "                                        &#x27;subsample&#x27;: [0.1, 0.2, 0.5, 0.6, 0.8,\n",
       "                                                      0.9]},\n",
       "                   random_state=168, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=GradientBoostingClassifier(), n_iter=100,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: [0.001, 0.01, 0.1, 0.5,\n",
       "                                                          0.6, 0.9],\n",
       "                                        &#x27;loss&#x27;: [&#x27;log_loss&#x27;, &#x27;exponential&#x27;],\n",
       "                                        &#x27;max_depth&#x27;: [1, 2, 3, 4, 5],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 3, 5],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 3, 4, 5, 6, 10,\n",
       "                                                              20],\n",
       "                                        &#x27;n_estimators&#x27;: [10, 100, 1000],\n",
       "                                        &#x27;subsample&#x27;: [0.1, 0.2, 0.5, 0.6, 0.8,\n",
       "                                                      0.9]},\n",
       "                   random_state=168, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=GradientBoostingClassifier(), n_iter=100,\n",
       "                   param_distributions={'learning_rate': [0.001, 0.01, 0.1, 0.5,\n",
       "                                                          0.6, 0.9],\n",
       "                                        'loss': ['log_loss', 'exponential'],\n",
       "                                        'max_depth': [1, 2, 3, 4, 5],\n",
       "                                        'max_features': ['sqrt', 'log2'],\n",
       "                                        'min_samples_leaf': [1, 2, 3, 5],\n",
       "                                        'min_samples_split': [2, 3, 4, 5, 6, 10,\n",
       "                                                              20],\n",
       "                                        'n_estimators': [10, 100, 1000],\n",
       "                                        'subsample': [0.1, 0.2, 0.5, 0.6, 0.8,\n",
       "                                                      0.9]},\n",
       "                   random_state=168, verbose=2)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%timeit\n",
    "# Create the hyperparameters to search over\n",
    "hyperparameters = {\n",
    "    'loss': ['log_loss', 'exponential'],\n",
    "    'learning_rate': [0.001, 0.01, 0.1, 0.5, 0.6, 0.9],\n",
    "    'n_estimators': [10, 100, 1000],\n",
    "    'min_samples_split': [2, 3, 4, 5, 6, 10, 20],\n",
    "    'min_samples_leaf': [1, 2, 3, 5],\n",
    "    'subsample': [0.1, 0.2, 0.5, 0.6, 0.8, 0.9],\n",
    "    'max_depth': [1, 2, 3, 4, 5],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "    \n",
    "}\n",
    "\n",
    "# Create the cross-validation object\n",
    "cv = RandomizedSearchCV(\n",
    "    estimator=GradientBoostingClassifier(),\n",
    "    param_distributions=hyperparameters,\n",
    "    n_iter=100,\n",
    "    cv=5,\n",
    "    verbose=2,\n",
    "    random_state=seed\n",
    ")\n",
    "\n",
    "# Fit the cross-validation object to the training data\n",
    "cv.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "2aa09af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.869071449605211 achieved with params: \n",
      "{'subsample': 0.9, 'n_estimators': 1000, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 3, 'loss': 'log_loss', 'learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "print(f'Best score: {cv.best_score_} achieved with params: \\n{cv.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b6452e",
   "metadata": {},
   "source": [
    "Train the final model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "642f295b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "dcdca467",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(max_features=&#x27;sqrt&#x27;, min_samples_split=4,\n",
       "                           n_estimators=1000, subsample=0.9)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(max_features=&#x27;sqrt&#x27;, min_samples_split=4,\n",
       "                           n_estimators=1000, subsample=0.9)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier(max_features='sqrt', min_samples_split=4,\n",
       "                           n_estimators=1000, subsample=0.9)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(**cv.best_params_)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67335fbb",
   "metadata": {},
   "source": [
    "# 3. Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047c2e7a",
   "metadata": {},
   "source": [
    "Test the final model using the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "562e103d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8751126033903858"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24ea7e7",
   "metadata": {},
   "source": [
    "# 4. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa26e7f",
   "metadata": {},
   "source": [
    "A major takeaway is that scaling numeric data doesn't necessarily help improve the model performance. This is probably due to the fact that the data range is not drastically different. \n",
    "\n",
    "To further improve the model's performance, we can use the cross-validation testing harness designed to test more different configurations, e.g. feature selection, other imputation strategies and tune even more hyperparameters with more options."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
